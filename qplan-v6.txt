QPlan v6
========
Rino Jose <@rjose>
Aug 31, 2013

Overview
--------
In v6, we should be working towards a number of things. The first is moving the
server portions out into link:https://github.com/rjose/catserve[catserve] and
tightening up the app code to provide "vending machine" views. The second is
rethinking our pipelines and coding them up in a more consistent way.

.Pipelines
The source data will ultimately come from a data source like a spreadsheet or
JIRA. Each team will organize their data differently. The first level of filters
will be custom for each team (and may need to be updated over time as the source
data evolves). It's totally appropriate for these scripts to refer to column
numbers and unpack specific fields. The goal of these frontline filters is to
transform the data into a known, consistent format.

The next set of filters will be written assuming the data has been conditioned
properly and is clean. I'm currently thinking these filters should be written in
Haskell. These filters will be application-specific. They will be able to
generate raw text reports and input data to vending machine apps.

We should support cases like this:

        - cat one-off chart with a chart-type header. The default action might
          be to emit JSON.
        - cat un-headered chart data but specifying flag


Implementation
--------------
. [X] Separate stacked streams into different types
. Emit data for first vending machine app
. Emit data for different types of live charts
. Emit different types of raw text reports


1 - Separate stacked streams into different types
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Let's start by just writing a filter that sends stdin to stdout. Done. What
should I name our main filter? It's going to be app-specific, so I guess qplan?
OK, so let's create a stacked stream test input. Done. OK, I got something that
works (it doesn't look too haskell-y yet, but it's a start). Let's check this
in. OK, let's follow along with
link:http://www.haskell.org/haskellwiki/Tutorials/Programming_Haskell/Argument_handling[
argument handling] to work with flags. Actually, the source code for the
link:http://www.haskell.org/ghc/docs/latest/html/libraries/base/System-Console-GetOpt.html[GetOpt
module] is very well-written, so I'm following along with that. All I want to do
is parse an option. Let's see if we can do this. Done!

Let's create a module that can split out stacked streams (and nested stack
streams). We'll do some basic testing and then hook it back into the main
program.

I think I should set up cabal first so it's easier to run the tests. Alright, I
can now do this to run tests:

        - cabal configure --enable-tests
        - cabal build
        - cabal test

I moved some files around to create the cabal module. Let's check in.

The next thing I want to do here is add a simple unit test for the stacked
streams. Done!

The last thing is to add documentation. Done.


2 - Emit data for first vending machine app
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
For this, we need stacked streams for Work and Staff. The columns for Work are
id, name, estimate, triage, and tags. The columns for Staff are id, name,
skills, and tags.

Within Haskell, we should be able to map a Work type constructor over the rows.
Once we have Work and Staff items, what can we do? We should do the
precomputation so lua doesn't need to. We should provide data to the app so that
we can totally shrink the handle_work_req function in web router. Here are some
things we should compute:

        - Get all tracks
        - Staff by track (along with available bandwidth)
        - Staff by skill
        - Work by skill
        - Work by track (along with manpower estimates)

Maybe we should have a generic dictionary for all of the work and staff and then
have tables that group by track, skill, triage. Maybe I could work backwards
from a new app and figure out what data I'd need to implement the same UI.

What part of this am I nervous about? I guess the construction of the new types.
Let's give this a try. I started out with Work. Before we go too much further,
let's create an Estimate module. I'll add a couple of tests to it and then
return. One thing that came up before is estimates vs skill supply. Is there a
generic word for both of these? Maybe SkillSize, SkillQuantity, SkillAmount? I
like SkillAmount the best. Let's go with this. OK, got something that can parse
strings. Let's see if we can define addition over SkillAmounts. Hmmm. This
doesn't feel correct. I think I may need to rethink this.


Thoughts
--------
How will the Haskell filters work with ad hoc reports? Not sure. If I wanted to
show shortage charts by track and then by theme, how would I do it? If I wanted
a one-off quad chart, what would I use to create the data? I think headers
should be used in every input stream. The headers define the format of the data.
I think we should be able to use the same haskell app repeatedly in a pipeline.
I'll have to see how this works.

For truly ad hoc reports, we should have custom shell scripts in whatever
language makes the most sense. However, for every language we use, we'll need a
way to parse the stacked streams.

We shouldn't have any unused data in the haskell input streams. If it's not
needed, it shouldn't be present. If it's needed in some cases and not in others,
then we should have different types of stacked streams for each case.

I want Haskell to do the heavy lifting. The vending machine apps should
essentially have "denormalized" data that's ready for consumption. The app
should do some level of computation, but it should almost always come from
upstream.

Action Items
------------
- Comment code according to Haddock style
